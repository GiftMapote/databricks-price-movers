{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "021bef8b-9c49-4a3c-9b3d-6726cb1deb16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## NOTEBOOK: 04_gold_aggregations\n",
    "#\n",
    "# GOAL:\n",
    "  Turn clean \"Silver\" data into \"Gold\" tables that are ready for dashboards and analytics.\n",
    "#\n",
    "### INPUT:\n",
    "- silver_prices  (one row per asset per pull)\n",
    "\n",
    "# ##OUTPUT:\n",
    "  - gold_hourly_prices  (hourly average per asset)\n",
    "  - gold_hourly_movers  (% change hour-over-hour per asset)\n",
    "\n",
    "### WHY GOLD?\n",
    "-  Gold is optimized for fast queries in dashboards.\n",
    "-   Instead of calculating aggregates every time, we precompute\n",
    "-   them once and store results in Delta tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65507459-9cc3-47b1-af3d-f5d4c3697db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set catalog and schemas\n",
    "spark.sql(\"USE CATALOG databricks_cata\")\n",
    "spark.sql(\"USE SCHEMA price_movers\")\n",
    "\n",
    "spark.sql(\"SELECT current_catalog(), current_schema()\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44a1e1b-7b54-4b75-9280-48924aaa2eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Silver and do sanity checks\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "silver = spark.table(\"silver_prices\")\n",
    "\n",
    "silver.select(\"asset_id\", \"event_ts\", \"event_ts_sa\", \"price\").orderBy(F.col(\"event_ts\").desc()).show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b1fca5-30a4-462a-bc16-e300058e3bd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create hourly price table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07b5ec8e-92b6-4fe3-a3f9-768b99448b4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hourly bucket based on event_ts (source time)\n",
    "# Create an hourly time bucket using event_ts.\n",
    "# This groups data into hourly windows like:\n",
    "# 2026-01-17 15:00:00\n",
    "# 2026-01-17 16:00:00\n",
    "\n",
    "#For eacg (asset_id, hour) we compute:\n",
    "# avg_price\n",
    "# min_price\n",
    "# max_price\n",
    "# samples\n",
    "\n",
    "# This table makes dashboars fast\n",
    "\n",
    "hourly = (\n",
    "    silver\n",
    "    .withColumn(\"hour_ts_sa\", F.date_trunc(\"hour\", F.col(\"event_ts_sa\")))\n",
    "    .groupBy(\"asset_id\",\"vs_currency\", \"hour_ts_sa\")\n",
    "    .agg(\n",
    "        F.avg(\"price\").alias(\"avg_price\"),\n",
    "        F.min(\"price\").alias(\"min_price\"),\n",
    "        F.max(\"price\").alias(\"max_price\"),\n",
    "        F.count(\"*\").alias(\"samples\")\n",
    "    )\n",
    ")\n",
    "\n",
    "hourly.orderBy(F.col(\"hour_ts_sa\").desc(), F.col(\"asset_id\")).show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1f6c915-04bd-4e0e-9895-0a40a49a5c0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Write gold_hourly_prices (Delta Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cc55643-73a5-436b-97ac-12d37f806c0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hourly.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(\"gold_hourly_prices\")\n",
    "\n",
    "print(\"Wrote Delta table: gold_hourly_prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2faf12ce-b5f5-4bc7-aa10-cb25dbb3af16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Compte hour-over-hour mover (percentage changes)\n",
    "\n",
    "For each asset, compare the current hour avg_price to the previous hour avg_price.\n",
    "\n",
    "pct_change = ((current - previous) / previous) * 100\n",
    "\n",
    "This will show most moving -> least moving on the dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdd9b6bc-97ee-4967-9605-a8661f88e43f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "gold_hourly = spark.table(\"gold_hourly_prices\")\n",
    "\n",
    "# Window lets us look at the previous row in time for each asset\n",
    "w = Window.partitionBy(\"asset_id\",\"vs_currency\").orderBy(\"hour_ts_sa\")\n",
    "\n",
    "movers = (\n",
    "    gold_hourly\n",
    "    .withColumn(\"prev_avg_price\", F.lag(\"avg_price\").over(w))\n",
    "    .withColumn(\n",
    "        \"pct_change\",\n",
    "        F.when(F.col(\"prev_avg_price\").isNull(), None)\n",
    "        .otherwise((F.col(\"avg_price\") - F.col(\"prev_avg_price\")) / F.col(\"prev_avg_price\") * 100)\n",
    "    )\n",
    "\n",
    "    # We only keep rowa where we have a previous hour to compare to\n",
    "    .where(F.col(\"prev_avg_price\").isNotNull())\n",
    ")\n",
    "# Preview sorted by latest hour and biggest moves\n",
    "movers.orderBy(F.col(\"hour_ts_sa\").desc(), F.col(\"pct_change\").desc()).show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "881432ff-0ce5-40ac-85b0-83acc95fcb1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Write gold_hourly_movers (Delta Table)\n",
    "\n",
    "- Save movers as a Gold table for the dashboard\n",
    "- This is what the Top Movers visual will query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52cd90ab-669a-4f7b-a515-287aae9b167b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "movers.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(\"gold_hourly_movers\")\n",
    "print(\"Wrote Delta Table: gold_hourly_movers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adf4dd43-0904-4a2a-be05-19c0009f0e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Validate Gold tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4001be88-40c6-4486-b033-2289805267e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS hourly_rows FROM gold_hourly_prices\").show()\n",
    "spark.sql(\"SELECT COUNT(*) AS movers_rows FROM gold_hourly_movers\").show()\n",
    "\n",
    "# Show latest movers\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT asset_id, vs_currency, hour_ts_sa, avg_price, prev_avg_price, pct_change\n",
    "FROM gold_hourly_movers\n",
    "ORDER BY hour_ts_sa DESC, pct_change DESC\n",
    "LIMIT 20\n",
    "\"\"\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_gold_aggregations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
